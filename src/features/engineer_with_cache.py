import pandas as pd
import numpy as np
from tqdm import tqdm
from src.utils.feature_cache import FeatureCacheManager


class FeatureEngineerWithCache:

    def __init__(self, windows, use_cache=True):
        """
        åˆå§‹åŒ–

        Args:
            windows: æ™‚é–“çª—å£åˆ—è¡¨(å¤©)
            use_cache: æ˜¯å¦ä½¿ç”¨ç·©å­˜
        """
        if not windows:
            raise ValueError('Windows list cannot be empty!')
        self.windows = windows
        self.use_cache = use_cache
        self.group_keys = ['card1', 'card2', 'addr1']
        self.agg_features = {
            'TransactionAmt': ['mean', 'std', 'min', 'max'],
            'TransactionID': ['count']
        }
        self.feature_names = []
        self.cache_mgr = FeatureCacheManager() if use_cache else None

    def create_feature(self, data, data_type='train', force_compute=False):
        """
        å‰µå»ºå¤šå°ºåº¦çª—å£ç‰¹å¾µ(å¸¶ç·©å­˜)

        Args:
            data: DataFrame
            data_type: è³‡æ–™é¡å‹(train/test)
            force_compute: å¼·åˆ¶é‡æ–°è¨ˆç®—(å¿½ç•¥ç·©å­˜)

        Returns:
            DataFrame: æ–°å¢ç‰¹å¾µå¾Œçš„è³‡æ–™
        """
        # æª¢æŸ¥ç·©å­˜
        if self.use_cache and not force_compute:
            if self.cache_mgr.cache_exists(self.windows, data_type):
                print(f'\nFound cached features for {data_type} data')
                cached_data = self.cache_mgr.load_cache(self.windows, data_type)

                # é©—è­‰è³‡æ–™å¤§å°æ˜¯å¦ä¸€è‡´
                if len(cached_data) == len(data):
                    print(f'  âœ“ Cache validated')
                    return cached_data
                else:
                    print(f'  Cache size mismatch, recomputing...')

        # è¨ˆç®—ç‰¹å¾µ
        print(f'\nğŸ”§ Computing window features for {data_type} data...')
        data = self._compute_features(data)

        # è™•ç†ç¼ºå¤±å€¼
        data = self._handle_missing_values(data)

        # å„²å­˜ç·©å­˜
        if self.use_cache:
            self.cache_mgr.save_cache(data, self.windows, data_type)

        return data

    def _compute_features(self, data):
        """å¯¦éš›è¨ˆç®—ç‰¹å¾µ"""
        print(f'  Windows: {self.windows} days')

        self.feature_names = []

        # ç¢ºä¿æŒ‰æ™‚é–“æ’åº
        data = data.sort_values('TransactionDT').reset_index(drop=True)
        feature_count = 0

        for group_key in tqdm(self.group_keys, desc='Group Keys'):
            if group_key not in data.columns:
                continue

            for window_days in self.windows:
                window_seconds = window_days * 24 * 3600

                for agg_col, agg_funcs in self.agg_features.items():
                    for agg_func in agg_funcs:
                        feat_name = f'{group_key}_{agg_col}_{agg_func}_{window_days}d'

                        # è¨ˆç®—ç‰¹å¾µ
                        data[feat_name] = data.groupby(group_key, observed=True).apply(
                            lambda x: self._rolling_agg(x, window_seconds, agg_col, agg_func),
                            include_groups=False
                        ).reset_index(level=0, drop=True)

                        self.feature_names.append(feat_name)
                        feature_count += 1

        print(f'  âœ“ Created {feature_count} features')

        return data

    def _rolling_agg(self, group_data, window_seconds, value_col, agg_func):
        """è¨ˆç®—æ»¾å‹•çª—å£èšåˆ"""
        result = []

        for idx, row in group_data.iterrows():
            current_time = row['TransactionDT']
            window_start = current_time - window_seconds

            window_data = group_data[
                (group_data['TransactionDT'] >= window_start) &
                (group_data['TransactionDT'] < current_time)
                ]

            if len(window_data) == 0:
                result.append(0 if agg_func == 'count' else np.nan)
            else:
                if agg_func == 'count':
                    result.append(len(window_data))
                elif agg_func == 'mean':
                    result.append(window_data[value_col].mean())
                elif agg_func == 'std':
                    result.append(window_data[value_col].std())
                elif agg_func == 'min':
                    result.append(window_data[value_col].min())
                elif agg_func == 'max':
                    result.append(window_data[value_col].max())
                else:
                    result.append(np.nan)

        return pd.Series(result, index=group_data.index)

    def _handle_missing_values(self, data):
        """è™•ç†çª—å£ç‰¹å¾µçš„ç¼ºå¤±å€¼"""
        nan_count = data.isnull().sum().sum()

        if nan_count > 0:
            print(f'  è™•ç† {nan_count} å€‹ç¼ºå¤±å€¼...')

            # åªè™•ç†æ–°å»ºçš„çª—å£ç‰¹å¾µ
            for feat_name in self.feature_names:
                if feat_name in data.columns:
                    # count ç‰¹å¾µç”¨ 0 å¡«è£œ(ä»£è¡¨æ²’æœ‰æ­·å²äº¤æ˜“)
                    if '_count_' in feat_name:
                        data[feat_name] = data[feat_name].fillna(0)
                        # std ç‰¹å¾µ: å–®ç­†äº¤æ˜“ç„¡æ³•è¨ˆç®—æ¨™æº–å·® â†’ å¡« 0
                    elif '_std_' in feat_name:
                        data[feat_name] = data[feat_name].fillna(0)
                    # çµ±è¨ˆç‰¹å¾µç”¨ 0 å¡«è£œ(ä»£è¡¨çª—å£å…§ç„¡è³‡æ–™)
                    else:
                        data[feat_name] = data[feat_name].fillna(0)

            print(f'  âœ“ ç¼ºå¤±å€¼è™•ç†å®Œæˆ')

        return data

    def get_feature_names(self):
        """ç²å–ç‰¹å¾µåç¨±"""
        return self.feature_names


if __name__ == '__main__':
    # ä¿®æ­£ import
    from src.data.datahandler import DataHandler

    # æ¸¬è©¦
    handler = DataHandler('datasets')
    train_data, test_data = handler.prepare_data()

    test_data = test_data.head(10000).copy()

    # ä½¿ç”¨ç·©å­˜
    engineer = FeatureEngineerWithCache(windows=[1], use_cache=True)

    # ç¬¬ä¸€æ¬¡:è¨ˆç®—ä¸¦ç·©å­˜
    print('\n--- First run ---')
    test_data = engineer.create_feature(test_data, data_type='test')

    # ç¬¬äºŒæ¬¡:å¾ç·©å­˜è®€å–
    print('\n--- Second run ---')
    test_data2 = engineer.create_feature(test_data.head(10000).copy(), data_type='test')